{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training an image classifier\n",
    "----------------------------\n",
    "\n",
    "We will do the following steps in order:\n",
    "\n",
    "1. Load and normalizing the MNIST training and test datasets using\n",
    "   ``torchvision``\n",
    "2. Define a neural network\n",
    "3. Define a loss function\n",
    "4. Train the network on the training data\n",
    "5. Test the network on the test data\n",
    "\n",
    "1. Loading and normalizing MNIST\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Using ``torchvision``, itâ€™s extremely easy to load MNIST.\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of torchvision datasets are PILImage images of range [0, 1].\n",
    "We transform them to Tensors of normalized range [-1, 1].\n",
    "60,000 training samples and 10,000 test samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Define a Neural Network\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "Three hidden layers, input size = height * width of the image,\n",
    "output size = the number of classes (which is 10 in the case of MNIST)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Use the base class: nn.Module\n",
    "\n",
    "The nn.Module mainly takes care of storing the paramters of the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(28 * 28, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # flatten image\n",
    "        x = x[:, 0, ...].view(-1, 28*28)\n",
    "        \n",
    "        # feed layer 1\n",
    "        out_layer1 = self.fc1(x)\n",
    "        out_layer1 = F.relu(out_layer1)\n",
    "        \n",
    "        # feed layer 2\n",
    "        out_layer2 = self.fc2(out_layer1)\n",
    "        out_layer2 = F.relu(out_layer2)\n",
    "        \n",
    "        # feed layer 3\n",
    "        out_layer3 = self.fc3(out_layer2)\n",
    "        \n",
    "        return out_layer3\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define a Loss function and optimizer\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "Let's use a Classification Cross-Entropy loss and SGD with momentum.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train the network\n",
    "^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "This is when things start to get interesting.\n",
    "We simply have to loop over our data iterator, and feed the inputs to the\n",
    "network and optimize.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,     1] loss: 0.000\n",
      "[1,   100] loss: 0.109\n",
      "[1,   199] loss: 0.132\n",
      "[1,   298] loss: 0.149\n",
      "[1,   397] loss: 0.159\n",
      "[1,   496] loss: 0.145\n",
      "[1,   595] loss: 0.102\n",
      "[1,   694] loss: 0.113\n",
      "[1,   793] loss: 0.163\n",
      "[1,   892] loss: 0.147\n",
      "[1,   991] loss: 0.101\n",
      "[1,  1090] loss: 0.069\n",
      "[1,  1189] loss: 0.205\n",
      "[1,  1288] loss: 0.128\n",
      "[1,  1387] loss: 0.085\n",
      "[1,  1486] loss: 0.082\n",
      "[1,  1585] loss: 0.100\n",
      "[1,  1684] loss: 0.149\n",
      "[1,  1783] loss: 0.131\n",
      "[1,  1882] loss: 0.161\n",
      "[1,  1981] loss: 0.118\n",
      "[1,  2080] loss: 0.147\n",
      "[1,  2179] loss: 0.127\n",
      "[1,  2278] loss: 0.120\n",
      "[1,  2377] loss: 0.085\n",
      "[1,  2476] loss: 0.053\n",
      "[1,  2575] loss: 0.141\n",
      "[1,  2674] loss: 0.115\n",
      "[1,  2773] loss: 0.117\n",
      "[1,  2872] loss: 0.113\n",
      "[1,  2971] loss: 0.086\n",
      "[1,  3070] loss: 0.132\n",
      "[1,  3169] loss: 0.138\n",
      "[1,  3268] loss: 0.120\n",
      "[1,  3367] loss: 0.150\n",
      "[1,  3466] loss: 0.127\n",
      "[1,  3565] loss: 0.186\n",
      "[1,  3664] loss: 0.083\n",
      "[1,  3763] loss: 0.085\n",
      "[1,  3862] loss: 0.106\n",
      "[1,  3961] loss: 0.096\n",
      "[1,  4060] loss: 0.120\n",
      "[1,  4159] loss: 0.130\n",
      "[1,  4258] loss: 0.082\n",
      "[1,  4357] loss: 0.145\n",
      "[1,  4456] loss: 0.129\n",
      "[1,  4555] loss: 0.096\n",
      "[1,  4654] loss: 0.074\n",
      "[1,  4753] loss: 0.205\n",
      "[1,  4852] loss: 0.088\n",
      "[1,  4951] loss: 0.146\n",
      "[1,  5050] loss: 0.139\n",
      "[1,  5149] loss: 0.085\n",
      "[1,  5248] loss: 0.109\n",
      "[1,  5347] loss: 0.111\n",
      "[1,  5446] loss: 0.111\n",
      "[1,  5545] loss: 0.089\n",
      "[1,  5644] loss: 0.089\n",
      "[1,  5743] loss: 0.080\n",
      "[1,  5842] loss: 0.122\n",
      "[1,  5941] loss: 0.103\n",
      "[1,  6040] loss: 0.074\n",
      "[1,  6139] loss: 0.100\n",
      "[1,  6238] loss: 0.202\n",
      "[1,  6337] loss: 0.135\n",
      "[1,  6436] loss: 0.133\n",
      "[1,  6535] loss: 0.119\n",
      "[1,  6634] loss: 0.115\n",
      "[1,  6733] loss: 0.149\n",
      "[1,  6832] loss: 0.151\n",
      "[1,  6931] loss: 0.113\n",
      "[1,  7030] loss: 0.152\n",
      "[1,  7129] loss: 0.141\n",
      "[1,  7228] loss: 0.153\n",
      "[1,  7327] loss: 0.081\n",
      "[1,  7426] loss: 0.082\n",
      "[1,  7525] loss: 0.125\n",
      "[1,  7624] loss: 0.118\n",
      "[1,  7723] loss: 0.130\n",
      "[1,  7822] loss: 0.110\n",
      "[1,  7921] loss: 0.149\n",
      "[1,  8020] loss: 0.099\n",
      "[1,  8119] loss: 0.078\n",
      "[1,  8218] loss: 0.090\n",
      "[1,  8317] loss: 0.116\n",
      "[1,  8416] loss: 0.066\n",
      "[1,  8515] loss: 0.078\n",
      "[1,  8614] loss: 0.112\n",
      "[1,  8713] loss: 0.082\n",
      "[1,  8812] loss: 0.124\n",
      "[1,  8911] loss: 0.107\n",
      "[1,  9010] loss: 0.121\n",
      "[1,  9109] loss: 0.080\n",
      "[1,  9208] loss: 0.099\n",
      "[1,  9307] loss: 0.120\n",
      "[1,  9406] loss: 0.091\n",
      "[1,  9505] loss: 0.126\n",
      "[1,  9604] loss: 0.196\n",
      "[1,  9703] loss: 0.087\n",
      "[1,  9802] loss: 0.077\n",
      "[1,  9901] loss: 0.074\n",
      "[1, 10000] loss: 0.125\n",
      "[1, 10099] loss: 0.111\n",
      "[1, 10198] loss: 0.102\n",
      "[1, 10297] loss: 0.175\n",
      "[1, 10396] loss: 0.072\n",
      "[1, 10495] loss: 0.152\n",
      "[1, 10594] loss: 0.144\n",
      "[1, 10693] loss: 0.107\n",
      "[1, 10792] loss: 0.103\n",
      "[1, 10891] loss: 0.103\n",
      "[1, 10990] loss: 0.112\n",
      "[1, 11089] loss: 0.141\n",
      "[1, 11188] loss: 0.076\n",
      "[1, 11287] loss: 0.080\n",
      "[1, 11386] loss: 0.120\n",
      "[1, 11485] loss: 0.111\n",
      "[1, 11584] loss: 0.118\n",
      "[1, 11683] loss: 0.094\n",
      "[1, 11782] loss: 0.112\n",
      "[1, 11881] loss: 0.095\n",
      "[1, 11980] loss: 0.081\n",
      "[1, 12079] loss: 0.091\n",
      "[1, 12178] loss: 0.144\n",
      "[1, 12277] loss: 0.091\n",
      "[1, 12376] loss: 0.073\n",
      "[1, 12475] loss: 0.068\n",
      "[1, 12574] loss: 0.119\n",
      "[1, 12673] loss: 0.085\n",
      "[1, 12772] loss: 0.107\n",
      "[1, 12871] loss: 0.120\n",
      "[1, 12970] loss: 0.143\n",
      "[1, 13069] loss: 0.162\n",
      "[1, 13168] loss: 0.075\n",
      "[1, 13267] loss: 0.076\n",
      "[1, 13366] loss: 0.111\n",
      "[1, 13465] loss: 0.132\n",
      "[1, 13564] loss: 0.083\n",
      "[1, 13663] loss: 0.075\n",
      "[1, 13762] loss: 0.140\n",
      "[1, 13861] loss: 0.067\n",
      "[1, 13960] loss: 0.109\n",
      "[1, 14059] loss: 0.134\n",
      "[1, 14158] loss: 0.121\n",
      "[1, 14257] loss: 0.120\n",
      "[1, 14356] loss: 0.093\n",
      "[1, 14455] loss: 0.130\n",
      "[1, 14554] loss: 0.062\n",
      "[1, 14653] loss: 0.130\n",
      "[1, 14752] loss: 0.137\n",
      "[1, 14851] loss: 0.144\n",
      "[1, 14950] loss: 0.189\n",
      "[2,     1] loss: 0.000\n",
      "[2,   100] loss: 0.091\n",
      "[2,   199] loss: 0.127\n",
      "[2,   298] loss: 0.090\n",
      "[2,   397] loss: 0.094\n",
      "[2,   496] loss: 0.085\n",
      "[2,   595] loss: 0.108\n",
      "[2,   694] loss: 0.085\n",
      "[2,   793] loss: 0.096\n",
      "[2,   892] loss: 0.084\n",
      "[2,   991] loss: 0.162\n",
      "[2,  1090] loss: 0.063\n",
      "[2,  1189] loss: 0.176\n",
      "[2,  1288] loss: 0.089\n",
      "[2,  1387] loss: 0.087\n",
      "[2,  1486] loss: 0.119\n",
      "[2,  1585] loss: 0.129\n",
      "[2,  1684] loss: 0.112\n",
      "[2,  1783] loss: 0.129\n",
      "[2,  1882] loss: 0.065\n",
      "[2,  1981] loss: 0.108\n",
      "[2,  2080] loss: 0.088\n",
      "[2,  2179] loss: 0.072\n",
      "[2,  2278] loss: 0.129\n",
      "[2,  2377] loss: 0.125\n",
      "[2,  2476] loss: 0.076\n",
      "[2,  2575] loss: 0.086\n",
      "[2,  2674] loss: 0.094\n",
      "[2,  2773] loss: 0.094\n",
      "[2,  2872] loss: 0.123\n",
      "[2,  2971] loss: 0.089\n",
      "[2,  3070] loss: 0.129\n",
      "[2,  3169] loss: 0.067\n",
      "[2,  3268] loss: 0.081\n",
      "[2,  3367] loss: 0.075\n",
      "[2,  3466] loss: 0.074\n",
      "[2,  3565] loss: 0.054\n",
      "[2,  3664] loss: 0.089\n",
      "[2,  3763] loss: 0.079\n",
      "[2,  3862] loss: 0.093\n",
      "[2,  3961] loss: 0.071\n",
      "[2,  4060] loss: 0.094\n",
      "[2,  4159] loss: 0.061\n",
      "[2,  4258] loss: 0.092\n",
      "[2,  4357] loss: 0.045\n",
      "[2,  4456] loss: 0.126\n",
      "[2,  4555] loss: 0.138\n",
      "[2,  4654] loss: 0.129\n",
      "[2,  4753] loss: 0.094\n",
      "[2,  4852] loss: 0.076\n",
      "[2,  4951] loss: 0.077\n",
      "[2,  5050] loss: 0.079\n",
      "[2,  5149] loss: 0.080\n",
      "[2,  5248] loss: 0.091\n",
      "[2,  5347] loss: 0.117\n",
      "[2,  5446] loss: 0.125\n",
      "[2,  5545] loss: 0.138\n",
      "[2,  5644] loss: 0.090\n",
      "[2,  5743] loss: 0.101\n",
      "[2,  5842] loss: 0.067\n",
      "[2,  5941] loss: 0.089\n",
      "[2,  6040] loss: 0.099\n",
      "[2,  6139] loss: 0.081\n",
      "[2,  6238] loss: 0.126\n",
      "[2,  6337] loss: 0.083\n",
      "[2,  6436] loss: 0.083\n",
      "[2,  6535] loss: 0.082\n",
      "[2,  6634] loss: 0.094\n",
      "[2,  6733] loss: 0.054\n",
      "[2,  6832] loss: 0.097\n",
      "[2,  6931] loss: 0.070\n",
      "[2,  7030] loss: 0.125\n",
      "[2,  7129] loss: 0.113\n",
      "[2,  7228] loss: 0.108\n",
      "[2,  7327] loss: 0.074\n",
      "[2,  7426] loss: 0.095\n",
      "[2,  7525] loss: 0.089\n",
      "[2,  7624] loss: 0.139\n",
      "[2,  7723] loss: 0.090\n",
      "[2,  7822] loss: 0.103\n",
      "[2,  7921] loss: 0.111\n",
      "[2,  8020] loss: 0.067\n",
      "[2,  8119] loss: 0.039\n",
      "[2,  8218] loss: 0.086\n",
      "[2,  8317] loss: 0.087\n",
      "[2,  8416] loss: 0.076\n",
      "[2,  8515] loss: 0.087\n",
      "[2,  8614] loss: 0.121\n",
      "[2,  8713] loss: 0.095\n",
      "[2,  8812] loss: 0.054\n",
      "[2,  8911] loss: 0.140\n",
      "[2,  9010] loss: 0.076\n",
      "[2,  9109] loss: 0.109\n",
      "[2,  9208] loss: 0.137\n",
      "[2,  9307] loss: 0.087\n",
      "[2,  9406] loss: 0.066\n",
      "[2,  9505] loss: 0.059\n",
      "[2,  9604] loss: 0.079\n",
      "[2,  9703] loss: 0.087\n",
      "[2,  9802] loss: 0.074\n",
      "[2,  9901] loss: 0.077\n",
      "[2, 10000] loss: 0.182\n",
      "[2, 10099] loss: 0.083\n",
      "[2, 10198] loss: 0.108\n",
      "[2, 10297] loss: 0.092\n",
      "[2, 10396] loss: 0.054\n",
      "[2, 10495] loss: 0.123\n",
      "[2, 10594] loss: 0.073\n",
      "[2, 10693] loss: 0.079\n",
      "[2, 10792] loss: 0.083\n",
      "[2, 10891] loss: 0.061\n",
      "[2, 10990] loss: 0.111\n",
      "[2, 11089] loss: 0.059\n",
      "[2, 11188] loss: 0.106\n",
      "[2, 11287] loss: 0.110\n",
      "[2, 11386] loss: 0.115\n",
      "[2, 11485] loss: 0.054\n",
      "[2, 11584] loss: 0.074\n",
      "[2, 11683] loss: 0.093\n",
      "[2, 11782] loss: 0.135\n",
      "[2, 11881] loss: 0.078\n",
      "[2, 11980] loss: 0.094\n",
      "[2, 12079] loss: 0.052\n",
      "[2, 12178] loss: 0.091\n",
      "[2, 12277] loss: 0.106\n",
      "[2, 12376] loss: 0.090\n",
      "[2, 12475] loss: 0.089\n",
      "[2, 12574] loss: 0.089\n",
      "[2, 12673] loss: 0.110\n",
      "[2, 12772] loss: 0.090\n",
      "[2, 12871] loss: 0.101\n",
      "[2, 12970] loss: 0.088\n",
      "[2, 13069] loss: 0.056\n",
      "[2, 13168] loss: 0.098\n",
      "[2, 13267] loss: 0.159\n",
      "[2, 13366] loss: 0.085\n",
      "[2, 13465] loss: 0.076\n",
      "[2, 13564] loss: 0.164\n",
      "[2, 13663] loss: 0.101\n",
      "[2, 13762] loss: 0.071\n",
      "[2, 13861] loss: 0.100\n",
      "[2, 13960] loss: 0.079\n",
      "[2, 14059] loss: 0.105\n",
      "[2, 14158] loss: 0.084\n",
      "[2, 14257] loss: 0.090\n",
      "[2, 14356] loss: 0.091\n",
      "[2, 14455] loss: 0.112\n",
      "[2, 14554] loss: 0.058\n",
      "[2, 14653] loss: 0.070\n",
      "[2, 14752] loss: 0.137\n",
      "[2, 14851] loss: 0.130\n",
      "[2, 14950] loss: 0.107\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 99 == 0:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Test the network on the test data\n",
    "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "\n",
    "We have trained the network for 2 passes over the training dataset.\n",
    "But we need to check if the network has learnt anything at all.\n",
    "\n",
    "We will check this by predicting the class label that the neural network\n",
    "outputs, and checking it against the ground-truth. If the prediction is\n",
    "correct, we add the sample to the list of correct predictions.\n",
    "\n",
    "Okay, first step. Let us display an image from the test set to get familiar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Performance on the test dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 0, 1, 3])\n",
      "    4     0     1     3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6bdcbaf908>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "predictions = net(images)\n",
    "\n",
    "_, predicted = torch.max(predictions.data, 1)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % predicted[j].item() for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
